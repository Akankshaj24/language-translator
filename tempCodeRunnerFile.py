#load  French model
# model = load_model('english_to_french_model')

# #load Tokenizer
# with open('english_tokenizer.json') as f:
#     data = json.load(f)
#     english_tokenizer = tokenizer_from_json(data)
    
# with open('french_tokenizer.json') as f:
#     data = json.load(f)
#     french_tokenizer = tokenizer_from_json(data)